{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffac3e3c-be33-43b9-8ee8-485db83f5c04",
   "metadata": {},
   "source": [
    "# A simple attention mechanism\n",
    "\n",
    "Uses only numpy.\n",
    "\n",
    "```mermaid\n",
    "graph TD;\n",
    "    A[Input text] --> B[Preprocessing steps];\n",
    "    B --> C[Self-attention module];\n",
    "    C -->D[Postprocessing steps <br> not implemented here];\n",
    "\n",
    "    style B fill:orange\n",
    "    style C fill:yellow, stroke-dasharray: 2 2\n",
    "    style D fill:gray;    \n",
    "```\n",
    "\n",
    "## TODO\n",
    "\n",
    "Preprocessing\n",
    "\n",
    "- [x] sample input\n",
    "- [x] convert tokens to naive embedding vectors\n",
    "\n",
    "\n",
    "Self-attention \n",
    "\n",
    "- [x] simple attention for a fixed query\n",
    "- [x] same for all queries w/ matrix multiplication\n",
    "- [ ] attention with trainable weights ($q$, $k$, $v$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ba68d-a0c1-4004-a6dd-10e36b8e80e3",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5787fa63-6b74-4c41-b009-547d6ae66bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea7bda9-7270-499b-9d0f-283e9b22467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many tokens?\n",
    "ntokens=4\n",
    "\n",
    "# dimensionality of embedding space\n",
    "dim=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8068d8-7a5e-4be7-947e-1fc07e26c242",
   "metadata": {},
   "source": [
    "**Input token**:\n",
    "(I am skipping the step of tokenizing a string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af62a950-c2f3-4d93-ab18-ab4a3a5ad383",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=np.random.randint(0, 100, size=ntokens, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47566525-22f3-453b-83f2-af36b2525e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72,  3, 64, 69])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee919c94-71cf-4456-afac-7c28745e92ef",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f6f81-815d-482f-942e-1e2d90a6fc5f",
   "metadata": {},
   "source": [
    "For the sake of going straight into implementing attention, I will skip the preprocessing steps of converting a token into an embedding vector. I will simply initialize vectors of dimension 3 with random numbers as components, according to the number of tokens provided.\n",
    "\n",
    "Here is a **random array representing the embedding vectors** $\\{x^{(i)}\\}$, where each line corresponds to a different vector $x^{(i)}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f35251f7-9c8f-4587-9b37-f748034d378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a matrix of size n x m with values between 0 and 1\n",
    "input = np.random.rand(ntokens, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7495b20f-7909-4aff-af73-cfe74a6b3a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86379499, 0.93042748, 0.82149658],\n",
       "       [0.11288872, 0.23407153, 0.26185969],\n",
       "       [0.79451453, 0.63626262, 0.39415654],\n",
       "       [0.59248056, 0.70135167, 0.51830873]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58076c7c-7114-46f0-a92b-bd48483f062b",
   "metadata": {},
   "source": [
    "## Self-attention for one query "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394eb01c-1d66-48aa-9c84-fb4775db3122",
   "metadata": {},
   "source": [
    "Specify which vector will be the query vector using the array index below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54164c31-b348-4c40-8b47-e625c6114a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qIndex=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b103e-6d2d-485c-a351-e67e7e11c855",
   "metadata": {},
   "source": [
    "Query vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc473090-a140-479e-9a22-cefc63b3bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=input[qIndex,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8b7c2-355e-4fcd-b665-32be2a10282a",
   "metadata": {},
   "source": [
    "### Attention scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d003b0-bedb-4615-bc53-758cf884c6a1",
   "metadata": {},
   "source": [
    "Let's do it first in the naive (computationally inefficient) way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e92855-3456-43c3-9ad3-7f63ef3bf452",
   "metadata": {},
   "source": [
    "Empty array that will hold the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32502664-79ab-4b84-9f64-d6f86141da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=np.empty(ntokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ba7f3-4e0b-4a35-ba24-6c783b3317af",
   "metadata": {},
   "source": [
    "Computes the dot product between the query vector and the entire set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80cb03b3-e50d-4a76-9717-332456bcfc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ntokens):\n",
    "    # `x` is a vector\n",
    "    x=input[i,:]\n",
    "\n",
    "    score[i]=x @ q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b6c0d30-b850-4854-b672-4c0cb6eab2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53041613, 0.13610384, 0.3418364 , 0.36677499])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e433c7c9-91df-4eef-a181-0cb07f75a27d",
   "metadata": {},
   "source": [
    "### Attention weights\n",
    "\n",
    "The attention weights are the normalized version of the score. We use the traditional `softmax` approach.\n",
    "\n",
    "First we define a naive softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df0bac7b-58c4-436f-ba01-550de87de28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    # ⚠️this is prone to overflow, needs to be improved\n",
    "    exps=np.exp(y)\n",
    "\n",
    "    return exps/exps.sum()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d87c5fa-4b36-4802-ac5e-bb16fb75a9fe",
   "metadata": {},
   "source": [
    "Then we get the actual weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebfc057e-88e6-493d-85d3-6f46c4fbd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=softmax(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fba40c1-95a3-4007-88b1-d87a50c73275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29838948, 0.20115732, 0.24710661, 0.25334659])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abe3ce-a867-4ca2-bd14-fd6c12d3350f",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "The context $z$ is the weighted sum $$z^{(i)} = \\sum_i \\alpha^{ij} x^{(j)}$$ where $\\alpha^{ij}$ are the attention weights for query index $i$ and $x^{(j)}$ are the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6ea46ed-7236-4f8d-99b5-a28e84381f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context=0\n",
    "for i in range(ntokens):\n",
    "    context+=weight[i]*input[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7db9d3f0-e756-4aed-a90f-d15db587c5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62688845, 0.65962472, 0.52651137])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62103e7-77c8-47de-9341-31acff707d99",
   "metadata": {},
   "source": [
    "## Attention for all queries\n",
    "\n",
    "Using matrix multiplication and thus more computationally-efficient.\n",
    "\n",
    "```mermaid\n",
    "graph TD;\n",
    "    A[1. Compute attention scores] --> B[2. Compute attention weights];\n",
    "    B --> C[3. Compute context vectors];\n",
    "    \n",
    "    style B fill:orange\n",
    "    style C fill:yellow;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e65237f-ead9-4921-96e6-00860b91ad61",
   "metadata": {},
   "source": [
    "### Attention scores\n",
    "\n",
    "Each line contains the scores for the query vector corresponding to that line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e3db15c-efef-49ba-8b1c-8af0c9e0170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=input@input.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba2bd2f5-8c60-4ff8-b695-d895370cca7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.28669371, 0.53041613, 1.60209215, 1.59012746],\n",
       "       [0.53041613, 0.13610384, 0.3418364 , 0.36677499],\n",
       "       [1.60209215, 0.3418364 , 1.19144284, 1.12127305],\n",
       "       [1.59012746, 0.36677499, 1.12127305, 1.11157133]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba36363-4412-41b5-b877-11a073e7266e",
   "metadata": {},
   "source": [
    "### Attention weights\n",
    "\n",
    "Yes, I know, using PyTorch would be faster and easier. But what would we be learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fe44429-6058-401b-9f6c-17861d6853bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=np.empty_like(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3540c1bf-5318-4d6b-aa51-114fd91fa117",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ntokens):\n",
    "    weights[i,:]=softmax(scores[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e142e36-979a-4ed8-a279-41221e639563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45971284, 0.07938619, 0.2318291 , 0.22907187],\n",
       "       [0.29838948, 0.20115732, 0.24710661, 0.25334659],\n",
       "       [0.38985174, 0.11055474, 0.25855726, 0.24103626],\n",
       "       [0.39375687, 0.11585984, 0.24638103, 0.24400226]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e344d50f-392b-46e9-aa42-32d69bae8a05",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e44f42cf-ad53-4fcd-bc50-26b27924a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts=weights@input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "929294fc-a110-41c5-9911-0bc618d7f5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72597167, 0.75447563, 0.60854748],\n",
       "       [0.62688845, 0.65962472, 0.52651137],\n",
       "       [0.69746917, 0.72216799, 0.57605494],\n",
       "       [0.69352439, 0.72137613, 0.57739014]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098213e-62bd-4e45-af6d-529e2088c0b5",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1575d5d7-585a-4bab-aa1b-f94ac63a540f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29838947615945444"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(score[0])/(np.sum(np.exp(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768ffb3-8669-46a4-b653-f473e162e4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
