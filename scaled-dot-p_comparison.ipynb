{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffac3e3c-be33-43b9-8ee8-485db83f5c04",
   "metadata": {},
   "source": [
    "# Scaled-dot product attention: Numpy vs PyTorch implementations\n",
    "\n",
    "- Considers weight matrices $W_{q,k,v}$ and query, key, values $q, k, v$\n",
    "- `conda activate pytorch` before this\n",
    "\n",
    "### TODO\n",
    "\n",
    "Self-attention \n",
    "\n",
    "- [x] attention with trainable weights ($q$, $k$, $v$)\n",
    "- [x] compare with pytorch class from book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ba68d-a0c1-4004-a6dd-10e36b8e80e3",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5787fa63-6b74-4c41-b009-547d6ae66bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da5f94-5369-41fb-9b8d-3af45dacb1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee342c0-f157-4748-bb2c-bbc99fab40ee",
   "metadata": {},
   "source": [
    "### Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea7bda9-7270-499b-9d0f-283e9b22467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many tokens?\n",
    "ntokens=4\n",
    "\n",
    "# dimensionality of token embedding space\n",
    "dim=3\n",
    "\n",
    "# dimensionality: qvk embeddings\n",
    "dk=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8068d8-7a5e-4be7-947e-1fc07e26c242",
   "metadata": {},
   "source": [
    "### Input token\n",
    "\n",
    "(I am skipping the step of tokenizing a string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af62a950-c2f3-4d93-ab18-ab4a3a5ad383",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=np.random.randint(0, 100, size=ntokens, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47566525-22f3-453b-83f2-af36b2525e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([79,  1, 14, 67])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee919c94-71cf-4456-afac-7c28745e92ef",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f6f81-815d-482f-942e-1e2d90a6fc5f",
   "metadata": {},
   "source": [
    "For the sake of going straight into implementing attention, I will skip the preprocessing steps of converting a token into an embedding vector. I will simply initialize vectors of dimension 3 with random numbers as components, according to the number of tokens provided.\n",
    "\n",
    "Here is a **random array representing the embedding vectors** $X$, where each line corresponds to a different vector $x^{(i)}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35251f7-9c8f-4587-9b37-f748034d378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a matrix of size n x m with values between 0 and 1\n",
    "input = np.random.rand(ntokens, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7495b20f-7909-4aff-af73-cfe74a6b3a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84711883, 0.29366239, 0.6859246 ],\n",
       "       [0.01094959, 0.91137307, 0.48771804],\n",
       "       [0.30762366, 0.60051404, 0.80047688],\n",
       "       [0.46252616, 0.94153513, 0.05022171]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141edfad-8b22-408c-ba8d-99af5ef626b3",
   "metadata": {},
   "source": [
    "## Initializes weight matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0787f1dd-54f0-4c9c-a085-acc876d40c10",
   "metadata": {},
   "source": [
    "Does this separately such that I can use them in my class and in the pytorch one, for the sake of comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85363560-ff22-4ab9-a38b-5885575ff7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_query=np.random.rand(dim, dk)\n",
    "W_key=np.random.rand(dim, dk)\n",
    "W_value=np.random.rand(dim, dk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4df35b-a39e-42d7-933c-04edab030542",
   "metadata": {},
   "source": [
    "## Based on numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51e223f0-c87a-495d-b64e-1e0fe466e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae3a4f-92ff-4241-94d2-a9fe14f7cb41",
   "metadata": {},
   "source": [
    "### Queries, keys and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a65ac6d-e4da-4cbc-a23b-70f9479e2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = x @ W_key\n",
    "queries = x @ W_query\n",
    "values = x @ W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "012616ef-4b76-4281-9ddc-2bab344325ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.04736787, 0.78204195],\n",
       "       [0.4219047 , 1.03244979],\n",
       "       [0.73243049, 0.91343069],\n",
       "       [0.59448109, 1.12181464]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed66c2f-db7f-4dc9-ba9f-14b414812f84",
   "metadata": {},
   "source": [
    "### Attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79f96557-ca84-470b-92e4-b5a4cbd43e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = queries @ keys.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "418c6229-9325-484a-8a8d-dfab0800bc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.61744518, 1.35153675, 1.48872608, 1.57951193],\n",
       "       [1.39766512, 1.10238484, 1.25296955, 1.30298844],\n",
       "       [1.67081042, 1.39618009, 1.53787067, 1.63167416],\n",
       "       [1.22167049, 0.87404728, 1.04945537, 1.05431901]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8136be41-d8cb-45bf-808b-316c14dd7ee1",
   "metadata": {},
   "source": [
    "### Softmax implementation\n",
    "\n",
    "This softmax implementation is dumb and slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87d65a82-5d39-459b-942a-9b09a62c872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(scores):\n",
    "    result=np.empty_like(scores)\n",
    "        \n",
    "    for i in range(scores.shape[0]):\n",
    "        exps=np.exp(scores[i,:])\n",
    "        result[i,:]=exps/exps.sum()\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77768249-e16f-45c4-88de-6691161de25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27712289, 0.21241728, 0.24365224, 0.2668076 ],\n",
       "       [0.28414938, 0.21149891, 0.24587039, 0.25848132],\n",
       "       [0.27801019, 0.21124687, 0.24340288, 0.26734006],\n",
       "       [0.29463193, 0.20811768, 0.24802059, 0.24922981]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(attn_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168aed19-a242-443d-b2ed-315a854d3902",
   "metadata": {},
   "source": [
    "### Attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1126a391-aec6-42a4-b1a9-3ec86dcfd8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = softmax(attn_scores / keys.shape[-1]**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3d67bd4-a963-4f91-a8f7-b822ffaea9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26916971, 0.22303226, 0.24575225, 0.26204578],\n",
       "       [0.27400623, 0.222373  , 0.24735774, 0.25626302],\n",
       "       [0.26979738, 0.22217786, 0.24559126, 0.2624335 ],\n",
       "       [0.28122913, 0.21994181, 0.24898565, 0.24984341]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51648418-2273-45ab-916c-97e20f5191bd",
   "metadata": {},
   "source": [
    "### Context vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "657ec911-63eb-4637-b150-de5ff6ca79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vec = attn_weights @ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c1d06a8-14b4-42d3-bcff-493c7e53aa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.04199908, 1.1026673 ],\n",
       "       [1.04514966, 1.10237919],\n",
       "       [1.04210659, 1.10270256],\n",
       "       [1.04925196, 1.10208835]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b7362c-e12c-4d5d-ac94-b369c6103fb1",
   "metadata": {},
   "source": [
    "## Compares with PyTorch result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0edfb21-1ff3-4114-b2ef-d92085f0c8ae",
   "metadata": {},
   "source": [
    "### PyTorch class from the book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a906c70-97e5-4720-bb43-5a1e8f07dc70",
   "metadata": {},
   "source": [
    "- `d_in`: embedding dimension of tokens\n",
    "- `d_out`: embedding dimensio of q,v,k vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210e328-e690-45d3-bc04-47a062b8f06d",
   "metadata": {},
   "source": [
    "This is the original class from the book:\n",
    "\n",
    "```python\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "```\n",
    "\n",
    "### Modified class\n",
    "\n",
    "However, I modified it such that it accepts as input the weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5f2137c-48f2-43b9-aceb-57dfdb31ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out, W_query, W_key, W_value):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.from_numpy(W_query).float())\n",
    "        self.W_key = nn.Parameter(torch.from_numpy(W_key).float())\n",
    "        self.W_value = nn.Parameter(torch.from_numpy(W_value).float())\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a749d50-5296-4852-a2f6-f0e76713a89d",
   "metadata": {},
   "source": [
    "Convert input from np to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5b04c18-e6c7-465c-bc9b-702cbea3e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTorch=torch.from_numpy(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abb5c74-5f4c-4f4c-92ef-3d6eaab1ab90",
   "metadata": {},
   "source": [
    "Use the class and get context vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f628cca8-dfa0-4c85-bf2f-83acff1922c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0420, 1.1027],\n",
       "        [1.0451, 1.1024],\n",
       "        [1.0421, 1.1027],\n",
       "        [1.0493, 1.1021]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(dim, dk, W_query, W_key, W_value)\n",
    "sa_v1(inputTorch.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e6d40c-7bc7-41e5-bd59-e84ef60a9263",
   "metadata": {},
   "source": [
    "### Compare with mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09eb7801-cdf5-4d32-ab1c-d522d56c1351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.04199908, 1.1026673 ],\n",
       "       [1.04514966, 1.10237919],\n",
       "       [1.04210659, 1.10270256],\n",
       "       [1.04925196, 1.10208835]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0e543-e024-4300-a996-27116fdf9b72",
   "metadata": {},
   "source": [
    "The difference is accounted by truncation error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098213e-62bd-4e45-af6d-529e2088c0b5",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768ffb3-8669-46a4-b653-f473e162e4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
